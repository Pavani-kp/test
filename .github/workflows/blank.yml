name: Run Tests and Extract Allure Summary (Windows)

on:
  workflow_dispatch:

jobs:
  allure-report:
    runs-on: windows-latest  # Use a Windows runner

    steps:
      # Step 1: Checkout the repository
      - name: Checkout repository
        uses: actions/checkout@v2

      # Step 2: Set up Python (if using pytest for tests)
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      # Step 3: Install dependencies (e.g., pytest, allure-pytest)
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest allure-pytest
          pip install -r requirements.txt
      
      - name: Install Scoop
        run: |
         Set-ExecutionPolicy RemoteSigned -scope CurrentUser
         iwr -useb get.scoop.sh | iex
         scoop install allure 
         echo $env:PATH 
         C:\Users\runneradmin\scoop\apps\allure\2.33.0\bin\allure.bat --version
      - name: Run tests with pytest and generate Allure results
        run: |
          pytest --alluredir=allure-results  # Specify the directory where results will be saved
        # Step 6: Generate the Allure report from the results
      - name: Upload Allure Results as artifact
        uses: actions/upload-artifact@v4
        with:
         name: allure-results
         path: allure-results/

      - name: Download Allure Results
        uses: actions/download-artifact@v4
        with:
         name: allure-results

      - name: Generate Allure Report
        run: |
         C:\Users\runneradmin\scoop\apps\allure\2.33.0\bin\allure.bat generate allure-results --clean -o allure-report  

      - name: Upload Allure Report as artifact
        uses: actions/upload-artifact@v4
        with:
         name: allure-report
         path: allure-report/

      - name: Download Allure Report
        uses: actions/download-artifact@v4
        with:
         name: allure-report

      - name: Deploy Allure Report to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
         github_token: ${{ secrets.GITHUB_TOKEN }}
         publish_dir: ./allure-report  # Path to the generated Allure report directory
         branch: gh-pages  # The branch where the report will be deployed
      - name: Post summary with build number
        run: |
          $LINK = "https://pavani-kp.github.io/test/"
          echo "Allure Results" >> $env:GITHUB_STEP_SUMMARY
          echo "$LINK" >> $env:GITHUB_STEP_SUMMARY
      - name: List allure-results directory
        run: |
          dir allure-results
      - name: Parse the First Allure Result File
        run: |
          echo "
          import json
          import os

          # Directory where the allure results are stored
          results_dir = 'allure-results'

          # List all files in the allure-results directory
          all_files = os.listdir(results_dir)

          # Filter out only the .json files (result files)
          json_files = [f for f in all_files if f.endswith('-result.json')]

          # Check if there are any result files
          if not json_files:
            print(f'{results_file} does not exist.')
          else:
            # Get the first .json file
           first_json_file = json_files[0]  # This is the first file in the list

          # Path to the first .json result file
          result_file_path = os.path.join(results_dir, first_json_file)

          with open(result_file_path) as f:
              results = json.load(f)
        
          # Initialize the pass count
          pass_count = 0

          # Loop through the 'tests' in the result data and count the passed ones
          for test_case in result_data.get('testCaseResults', []):
          # Check if the test case status is 'passed'
          if test_case.get('status') == 'passed':
            pass_count += 1
          # Output the pass count
          print(f"Total passed tests in {first_json_file}: {pass_count}")
          " > count_passed_tests.py

      - name: Run Python script to count passed tests
        run: python count_passed_tests.py
